{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Autocorrector Feature Using NLP**\n",
        "\n",
        "About this project: Autocorrect is a way of predicting or making the wrong spellings correct, which makes the tasks like writing paragraphs, reports, and articles easier. This project utilizes Machine Learning and NLP to make an autocorrection generator that suggests the user the correct spelling for an input word."
      ],
      "metadata": {
        "id": "LO-Esab8EkSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the text file that will be used to create word list\n",
        "# importing regular expression\n",
        "import re\n",
        "\n",
        "# words\n",
        "w = []\n",
        "\n",
        "# reading text file\n",
        "with open('final.txt', 'r', encoding=\"utf8\") as f:\n",
        "    file_name_data = f.read()\n",
        "    file_name_data = file_name_data.lower()\n",
        "    w = re.findall('\\w+', file_name_data)\n",
        "\n",
        "# vocabulary\n",
        "main_set = set(w)"
      ],
      "metadata": {
        "id": "OpiGSy-jA9Om"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to count the frequency of the words in the whole text file\n",
        "\n",
        "\n",
        "def counting_words(words):\n",
        "    word_count = {}\n",
        "    for word in words:\n",
        "        if word in word_count:\n",
        "            word_count[word] += 1\n",
        "        else:\n",
        "            word_count[word] = 1\n",
        "    return word_count"
      ],
      "metadata": {
        "id": "qmczA2VTBBWK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the probability of each word\n",
        "def prob_cal(word_count_dict):\n",
        "    probs = {}\n",
        "    m = sum(word_count_dict.values())\n",
        "    for key in word_count_dict.keys():\n",
        "        probs[key] = word_count_dict[key] / m\n",
        "    return probs"
      ],
      "metadata": {
        "id": "3GxjOIrCBBf3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install pattern\n",
        "# Getting into 5 parts that includes creation of all types of different words\n"
      ],
      "metadata": {
        "id": "ey5_hcdgBBnr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1 Lemmatization\n",
        "#LemmWord: extracting and adding\n",
        "# root word i.e.Lemma using pattern module\n",
        "\n",
        "import pattern\n",
        "from pattern.en import lemma, lexeme\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "def LemmWord(word):\n",
        "    return list(lexeme(wd) for wd in word.split())[0]"
      ],
      "metadata": {
        "id": "49sXIaiQBhIW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2 Deletion\n",
        "# Deleting letters from the words\n",
        "\n",
        "def DeleteLetter(word):\n",
        "    delete_list = []\n",
        "    split_list = []\n",
        "\n",
        "    # considering letters 0 to i then i to -1\n",
        "    # Leaving the ith letter\n",
        "    for i in range(len(word)):\n",
        "        split_list.append((word[0:i], word[i:]))\n",
        "\n",
        "    for a, b in split_list:\n",
        "        delete_list.append(a + b[1:])\n",
        "    return delete_list"
      ],
      "metadata": {
        "id": "FqjxZFs8BhK8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 3 Swapping Letter\n",
        "\n",
        "# Switching two letters in a word\n",
        "def Switch_(word):\n",
        "    split_list = []\n",
        "    switch_l = []\n",
        "\n",
        "    #creating pair of the words(and breaking them)\n",
        "    for i in range(len(word)):\n",
        "        split_list.append((word[0:i], word[i:]))\n",
        "\n",
        "    #Printint the first word (i.e. a)\n",
        "    #then replacing the first and second character of b\n",
        "    switch_l = [a + b[1] + b[0] + b[2:] for a, b in split_list if len(b) >= 2]\n",
        "    return switch_l"
      ],
      "metadata": {
        "id": "RSGWTupFBhNS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 4 Replace Letter\n",
        "\n",
        "def Replace_(word):\n",
        "    split_l = []\n",
        "    replace_list = []\n",
        "\n",
        "    # Replacing the letter one-by-one from the list of alphs\n",
        "    for i in range(len(word)):\n",
        "        split_l.append((word[0:i], word[i:]))\n",
        "    alphs = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    replace_list = [a + l + (b[1:] if len(b) > 1 else '')\n",
        "                    for a, b in split_l if b for l in alphs]\n",
        "    return replace_list"
      ],
      "metadata": {
        "id": "Moxyuc69BhPp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 5 Inserting New Letter\n",
        "\n",
        "def insert_(word):\n",
        "    split_l = []\n",
        "    insert_list = []\n",
        "\n",
        "    # Making pairs of the split words\n",
        "    for i in range(len(word) + 1):\n",
        "        split_l.append((word[0:i], word[i:]))\n",
        "\n",
        "    # Storing new words in a list\n",
        "    # But one new character at each location\n",
        "    alphs = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    insert_list = [a + l + b for a, b in split_l for l in alphs]\n",
        "    return insert_list"
      ],
      "metadata": {
        "id": "ez2PJOGlCWvn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now merging all the words (functions) from Part 1-5"
      ],
      "metadata": {
        "id": "nYbk5sjeCW7V"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collecting all the words in a set(so that no word will repeat)\n",
        "\n",
        "def colab_1(word, allow_switches=True):\n",
        "    colab_1 = set()\n",
        "    colab_1.update(DeleteLetter(word))\n",
        "    if allow_switches:\n",
        "        colab_1.update(Switch_(word))\n",
        "    colab_1.update(Replace_(word))\n",
        "    colab_1.update(insert_(word))\n",
        "    return colab_1\n",
        "\n",
        "# collecting words using by allowing switches\n",
        "\n",
        "def colab_2(word, allow_switches=True):\n",
        "    colab_2 = set()\n",
        "    edit_one = colab_1(word, allow_switches=allow_switches)\n",
        "    for w in edit_one:\n",
        "        if w:\n",
        "            edit_two = colab_1(w, allow_switches=allow_switches)\n",
        "            colab_2.update(edit_two)\n",
        "    return colab_2"
      ],
      "metadata": {
        "id": "4a0yufWPCxJX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next: Extracting correct word among all"
      ],
      "metadata": {
        "id": "t-Bxyuh2C9C1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only storing those values which are in the vocab\n",
        "\n",
        "def get_corrections(word, probs, vocab, n=2):\n",
        "    suggested_word = []\n",
        "    best_suggestion = []\n",
        "    suggested_word = list(\n",
        "        (word in vocab and word) or colab_1(word).intersection(vocab)\n",
        "        or colab_2(word).intersection(\n",
        "            vocab))\n",
        "\n",
        "    # finding out the words with high frequencies\n",
        "    best_suggestion = [[s, probs[s]] for s in list(reversed(suggested_word))]\n",
        "    return best_suggestion"
      ],
      "metadata": {
        "id": "raZZ_7spCxNj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING Code\n",
        "\n",
        "# Input\n",
        "my_word = input(\"Enter any word:\")\n",
        "\n",
        "# Counting word function\n",
        "word_count = counting_words(main_set)\n",
        "\n",
        "# Calculating probability\n",
        "probs = prob_cal(word_count)\n",
        "\n",
        "# only storing correct words\n",
        "tmp_corrections = get_corrections(my_word, probs, main_set, 2)\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    if(i < 3):\n",
        "        print(word_prob[0])\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfPeZRP_DHMT",
        "outputId": "5d6a027e-ccbb-454d-85d9-d0ac1467fdbd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter any word:repot\n",
            "depot\n",
            "repet\n",
            "report\n"
          ]
        }
      ]
    }
  ]
}